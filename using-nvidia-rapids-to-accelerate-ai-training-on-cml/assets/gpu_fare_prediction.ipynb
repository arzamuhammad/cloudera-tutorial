{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excited-fleece",
   "metadata": {},
   "source": [
    "# Licencing Information\n",
    "\n",
    "(C) Cloudera, Inc. 2020-2021\n",
    "All rights reserved.\n",
    "\n",
    "Applicable Open Source License: GNU Affero General Public License v3.0\n",
    "\n",
    "NOTE: Cloudera open source products are modular software products\n",
    "made up of hundreds of individual components, each of which was\n",
    "individually copyrighted.  Each Cloudera open source product is a\n",
    "collective work under U.S. Copyright Law. Your license to use the\n",
    "collective work is as provided in your written agreement with\n",
    "Cloudera.  Used apart from the collective work, this file is\n",
    "licensed for your use pursuant to the open source license\n",
    "identified above.\n",
    "\n",
    "This code is provided to you pursuant a written agreement with\n",
    "(i) Cloudera, Inc. or (ii) a third-party authorized to distribute\n",
    "this code. If you do not have a written agreement with Cloudera nor\n",
    "with an authorized and properly licensed third party, you do not\n",
    "have any rights to access nor to use this code.\n",
    "\n",
    "Absent a written agreement with Cloudera, Inc. (“Cloudera”) to the\n",
    "contrary, A) CLOUDERA PROVIDES THIS CODE TO YOU WITHOUT WARRANTIES OF ANY\n",
    "KIND; (B) CLOUDERA DISCLAIMS ANY AND ALL EXPRESS AND IMPLIED\n",
    "WARRANTIES WITH RESPECT TO THIS CODE, INCLUDING BUT NOT LIMITED TO\n",
    "IMPLIED WARRANTIES OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY AND\n",
    "FITNESS FOR A PARTICULAR PURPOSE; (C) CLOUDERA IS NOT LIABLE TO YOU,\n",
    "AND WILL NOT DEFEND, INDEMNIFY, NOR HOLD YOU HARMLESS FOR ANY CLAIMS\n",
    "ARISING FROM OR RELATED TO THE CODE; AND (D)WITH RESPECT TO YOUR EXERCISE\n",
    "OF ANY RIGHTS GRANTED TO YOU FOR THE CODE, CLOUDERA IS NOT LIABLE FOR ANY\n",
    "DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, PUNITIVE OR\n",
    "CONSEQUENTIAL DAMAGES INCLUDING, BUT NOT LIMITED TO, DAMAGES\n",
    "RELATED TO LOST REVENUE, LOST PROFITS, LOSS OF INCOME, LOSS OF\n",
    "BUSINESS ADVANTAGE OR UNAVAILABILITY, OR LOSS OR CORRUPTION OF\n",
    "DATA.\n",
    "\n",
    "Source File Name: gpu_fare_prediction.ipynb\n",
    "\n",
    "Description: Explore how you can leverage NVIDIA's RAPIDS framework\n",
    "             using Cloudera Machine Learning (CML), on the Cloudera Data Platform (CDP).\n",
    "\n",
    "Author(s): Jacob (Jake) Bengtson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-sapphire",
   "metadata": {},
   "source": [
    "# Program Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variable that will determine if CPUs or GPUs will be used\n",
    "mode = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from math import cos, sin, asin, sqrt, pi\n",
    "\n",
    "if mode is 'cpu':\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import r2_score\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "elif mode is 'gpu':\n",
    "    import cudf as pd\n",
    "    import cupy as np\n",
    "    from cuml import train_test_split\n",
    "    from cuml.linear_model import LinearRegression\n",
    "    from cuml.metrics.regression import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 24\n",
    "year = 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-trustee",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "Import data only once. After you import the data, this step can be skipped or commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from urllib import request\n",
    "for month in range(1,3):\n",
    "    request.urlretrieve(\"https://s3.amazonaws.com/nyc-tlc/trip+data/\" + \\\n",
    "                        \"yellow_tripdata_%s-{0:0=2d}.csv\".format(month) % year,\n",
    "                        \"./yellow_tripdata_%s-{0:0=2d}.csv\".format(month) % year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-mississippi",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = datetime.now()\n",
    "# pandas does not handle null values in int columns, so I had to use floats\n",
    "dtypes = {\n",
    "    'tpep_pickup_datetime': 'str',\n",
    "    'tpep_dropoff_datetime': 'str',\n",
    "    'passenger_count': 'float32',\n",
    "    'trip_distance': 'float32',\n",
    "    'RateCodeID': 'str',\n",
    "    'pickup_longitude': 'float32',\n",
    "    'pickup_latitude': 'float32',\n",
    "    'dropoff_longitude': 'float32',\n",
    "    'dropoff_latitude': 'float32',\n",
    "    'payment_type': 'str',\n",
    "    'fare_amount': 'float32'\n",
    "}\n",
    "\n",
    "# the one difference that I found between cudf and pandas\n",
    "if mode is 'gpu':\n",
    "    dtypes.update({\n",
    "        'tpep_pickup_datetime': 'date',\n",
    "        'tpep_dropoff_datetime': 'date',\n",
    "    })\n",
    "\n",
    "taxi_glob = glob('./*%s*.csv' % year)\n",
    "li = []\n",
    "for file in taxi_glob:\n",
    "    temp_df = pd.read_csv(file,\n",
    "                          usecols=list(dtypes.keys()),\n",
    "                          dtype=dtypes,\n",
    "                          parse_dates=['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    "                         )\n",
    "    li.append(temp_df)\n",
    "\n",
    "taxi_df = pd.concat(li, ignore_index=True)\n",
    "del li\n",
    "del temp_df\n",
    "\n",
    "print('Dataframe row count: ' + str(taxi_df.shape[0]))\n",
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# clean up column names\n",
    "taxi_df.rename(\n",
    "    columns={\n",
    "        'tpep_pickup_datetime': 'pickup_datetime',\n",
    "        'tpep_dropoff_datetime': 'dropoff_datetime',\n",
    "        'RateCodeID': 'ratecode_id'\n",
    "    },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# filter out outliers based on previously performed EDA\n",
    "# filter out lot/long outside of NYC\n",
    "filters = [\n",
    "    'fare_amount > 1 and fare_amount < 500',\n",
    "    'passenger_count > 0 and passenger_count < 6',\n",
    "    'trip_distance > 0 and trip_distance < 500',\n",
    "    'not (trip_distance > 50 and fare_amount < 50)',\n",
    "    'not (trip_distance < 10 and fare_amount > 300)',\n",
    "    'not dropoff_datetime <= pickup_datetime',\n",
    "    'pickup_longitude <= 73.4 and pickup_longitude >= -74.4',\n",
    "    'pickup_latitude <= 41.2 and pickup_latitude >= 40.2'\n",
    "]\n",
    "taxi_df = taxi_df.query(' and '.join(filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# one hot encode: ratecode_id, payment_type\n",
    "dummy_df = pd.get_dummies(taxi_df['ratecode_id'], prefix='ratecode_id')\n",
    "dummy_df2 = pd.get_dummies(taxi_df['payment_type'], prefix='payment_type')\n",
    "taxi_df.drop(['ratecode_id', 'payment_type'], axis=1, inplace=True)\n",
    "taxi_df = pd.concat([taxi_df, dummy_df, dummy_df2], axis=1)\n",
    "del dummy_df, dummy_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# add time features\n",
    "taxi_df['hour'] = taxi_df['pickup_datetime'].dt.hour\n",
    "taxi_df['month'] = taxi_df['pickup_datetime'].dt.month\n",
    "taxi_df['day'] = taxi_df['pickup_datetime'].dt.day\n",
    "taxi_df['day_of_week'] = taxi_df['pickup_datetime'].dt.weekday\n",
    "taxi_df['is_weekend'] = (taxi_df['day_of_week']>=5).astype('int32')\n",
    "taxi_df['diff'] = taxi_df['dropoff_datetime'].astype('int64') - taxi_df['pickup_datetime'].astype('int64')\n",
    "taxi_df['diff']=(taxi_df['diff']/1000).astype('int64')\n",
    "taxi_df = taxi_df.drop(['pickup_datetime', 'dropoff_datetime'], axis=1)\n",
    "# add trip direction features\n",
    "taxi_df['toward_east'] = ((taxi_df[\"dropoff_longitude\"] - taxi_df[\"pickup_longitude\"]) * 85) > 0\n",
    "taxi_df['toward_north'] = ((taxi_df[\"dropoff_latitude\"] - taxi_df[\"pickup_latitude\"]) * 111) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# add haversine distance feature\n",
    "# Haversine distance formula taken from Michael Dunn's StackOverflow post:\n",
    "# https://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "if mode is 'cpu':\n",
    "    def haversine_distance(x_1, y_1, x_2, y_2):\n",
    "        x_1 = pi/180 * x_1\n",
    "        y_1 = pi/180 * y_1\n",
    "        x_2 = pi/180 * x_2\n",
    "        y_2 = pi/180 * y_2\n",
    "        \n",
    "        dlon = y_2 - y_1\n",
    "        dlat = x_2 - x_1\n",
    "        a = sin(dlat/2)**2 + cos(x_1) * cos(x_2) * sin(dlon/2)**2\n",
    "        \n",
    "        c = 2 * asin(sqrt(a)) \n",
    "        r = 6371 # Radius of earth in kilometers\n",
    "        return c * r\n",
    "    \n",
    "    taxi_df['hav_distance'] = taxi_df.apply(lambda row:haversine_distance(row['pickup_latitude'],\n",
    "                                                                        row['pickup_longitude'],\n",
    "                                                                        row['dropoff_latitude'],\n",
    "                                                                        row['dropoff_longitude']),axis=1)\n",
    "    \n",
    "elif mode is 'gpu':\n",
    "    def haversine_distance(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude, hav_distance):\n",
    "        for i, (x_1, y_1, x_2, y_2) in enumerate(zip(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude)):\n",
    "\n",
    "            x_1 = pi/180 * x_1\n",
    "            y_1 = pi/180 * y_1\n",
    "            x_2 = pi/180 * x_2\n",
    "            y_2 = pi/180 * y_2\n",
    "\n",
    "            dlon = y_2 - y_1\n",
    "            dlat = x_2 - x_1\n",
    "            a = sin(dlat/2)**2 + cos(x_1) * cos(x_2) * sin(dlon/2)**2\n",
    "\n",
    "            c = 2 * asin(sqrt(a)) \n",
    "            r = 6371 # Radius of earth in kilometers\n",
    "\n",
    "            hav_distance[i] = c * r\n",
    "\n",
    "    taxi_df = taxi_df.apply_rows(haversine_distance,\n",
    "                               incols=['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'],\n",
    "                               outcols=dict(hav_distance=np.float64),\n",
    "                               kwargs=dict())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset Row Count: %s' % taxi_df.shape[0])\n",
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-segment",
   "metadata": {},
   "source": [
    "# Train and Evaluate a Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create a test set for evaluation\n",
    "y = taxi_df.pop('fare_amount')\n",
    "X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(taxi_df, y, test_size=.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit and score model\n",
    "lr_model = LinearRegression(fit_intercept=True,\n",
    "                            normalize=True)\n",
    "lr_model.fit(X_df_train, y_df_train)\n",
    "y_hat = lr_model.predict(X_df_test)\n",
    "print(r2_score(y_df_test, y_hat))\n",
    "del X_df_train, X_df_test, y_df_train, y_df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-maple",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train model on full data set\n",
    "lr_model_full = LinearRegression(fit_intercept=True,\n",
    "                                 normalize=True)\n",
    "lr_model_full.fit(taxi_df, y)\n",
    "\n",
    "# Save Model\n",
    "mdl = pickle.dumps(lr_model_full)\n",
    "with open('%s_taxi_model.pickle' % mode, 'wb') as handle:\n",
    "    pickle.dump(mdl, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%s run time: %s' % (mode, (datetime.now() - start_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
